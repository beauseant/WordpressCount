{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import *\n\n\npath = '/FileStore/tables/fhyjgcr41467271069254/wp_posts.csv'\npath= '/FileStore/tables/443875ud1470308850012/wp_posts.csv'\npath='/FileStore/tables/8904hajl1470383389657/wp_posts4.csv'\nscheme = None\n        \nif scheme == None:\n    inferS = True\n    \ncustomSchema = StructType([\n  StructField('id', StringType(), True),\n  StructField('author_id', StringType(), True),\n  StructField('post_date', StringType(), True),\n  StructField('post_date_gmt', StringType(), True),\n  StructField('post_content', StringType(), True),\n  StructField('post_title', StringType(), True),\n  StructField('post_category', StringType(), True),\n  StructField('post_excerpt', StringType(), True),\n  StructField('post_status', StringType(), True),\n  StructField('comment_status', StringType(), True),\n  StructField('ping_status', StringType(), True),\n  StructField('post_password', StringType(), True),\n  StructField('post_name', StringType(), True),\n  StructField('to_ping', StringType(), True),\n  StructField('pinged', StringType(), True),\n  StructField('post_modifed', StringType(), True),    \n  StructField('post_modifed_gmt', StringType(), True),\n  StructField('post_content_filtered', StringType(), True),\n  StructField('post_parent', StringType(), True),\n  StructField('guid', StringType(), True),    \n  StructField('menu_ordered', StringType(), True),    \n  StructField('post_type', StringType(), True),\n  StructField('post_mime_type', StringType(), True),\n  StructField('comment_count', StringType(), True)\n  ])\n\n    \nallData = sqlContext.read.format('com.databricks.spark.csv').options(parserLib='univocity', header='false', delimiter=';', quote='\"').schema (customSchema).load(path, inferSchema=False)\n\n\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["from pyspark.sql.functions import year\nfrom datetime import datetime\n\ndef setYear ( d ):\n  try:\n    dtDate = datetime.strptime(d, \"%Y-%m-%d %H:%M:%S\").year\n  except:\n    dtDate = 'None'\n  return dtDate\n\nsetYearUDF = udf(setYear, StringType())\n\nposts = allData.select ('*').where (\"post_type = 'post'\").withColumn ('post_year', setYearUDF('post_date'))\npages = allData.select ('*').where (\"post_type = 'page'\")\n\ncurYear = '2016'\nyearPosts =  posts.select ('*').where (\"post_year='\" + curYear +\"'\").cache ()\nnotValid = posts.select ('*').where (\"post_year='None'\")\n\nprint 'we have %s posts and %s pages. %s in the selected year (%s)' % ( posts.count(), pages.count(), yearPosts.count(), curYear )\nprint 'not valid %s' % (notValid.count())\n\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark.sql.functions import regexp_replace, trim, col, lower\nimport re\nimport lxml.html\n\ndef strip_markdown(x):\n  try:\n    return re.sub(\"<.*?>\", \"\", x)\n  except:\n    return 'none'\n    \n\n\n\nremoveTagsUDF = udf (strip_markdown, StringType())  \n\ndef removePunctuation(column):\n    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n\n    Note:\n        Only spaces, letters, and numbers should be retained.  Other characters should should be\n        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n        punctuation is removed.\n\n    Args:\n        column (Column): A Column containing a sentence.\n\n    Returns:\n        Column: A Column named 'sentence' with clean-up operations applied.\n    \"\"\"\n    #return re.sub( '[^a-z0-9 ]', \"\", text.lower().strip())\n    #return trim (lower (column))\n    return  (regexp_replace (trim (lower(column)),'[^a-z0-9 áéíóúñ ]', ' ' )).alias ('sentence')\n\n  \n  \n  "],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.sql.functions import split, explode\n\ncontent = yearPosts.withColumn ('post_content', removeTagsUDF('post_content')).select(removePunctuation(col('post_content'))).cache()\n\nwords = (content\n                .select(explode (split ('sentence', ' ')).alias ('word'))\n               ).where (\"word<>''\")\n\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["words.show()\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["from pyspark.sql.functions import desc\ntopWords = words.groupBy ('word').count().orderBy( desc ('count') ).cache()\n\n\nprint topWords.show()\n\nprint 'total words: %s' % (topWords.count())"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["path = '/FileStore/tables/5a7qt6081470299078502/stopwords.txt'\n\nstopWords = sqlContext.read.format('com.databricks.spark.csv').options(parserLib='univocity', header='false', delimiter=';').load(path, inferSchema=True)\ncleanWords = topWords.join(stopWords,topWords.word == stopWords.C0, 'outer').where(\"C0 is null\").orderBy( desc('count')).drop ('C0')\n\nprint 'Total words before clean %s, num stop words %s, total words affter clean %s' % (topWords.count(), stopWords.count(), cleanWords.count())\nprint cleanWords.show(200)\n\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["cleanWords.where(\"word='días'\").show()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["\ndf = sqlContext.createDataFrame(\n    [(1, \"a\", 23.0), (3, \"B\", -23.0),(8, \"D\", -2.0),(16, \"J\", -3.0)], (\"x1\", \"x2\", \"x3\"))\n\ndf.show()\n\ndf.registerTempTable('principal')\n\ndf2 = sqlContext.sql ('SELECT ROW_NUMBER() OVER () AS rn, x1,x2,x3 FROM principal')\ndf3 = sqlContext.sql ('SELECT ROW_NUMBER() OVER ( ORDER BY x2 ) AS rn, x1,x2,x3 FROM principal')\ndf2.show ()\ndf3.show ()\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["df3.orderBy('x2','x3').show()\nsqlContext.sql ('SELECT * FROM principal ORDER BY x2,x3').show()\n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["%run \"/Users/suscripcion@bluethinking.com/functions\""],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["print suma(4,6)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["suma(4,3)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":15}],"metadata":{"name":"WordpressCount","notebookId":2569913109911296},"nbformat":4,"nbformat_minor":0}
